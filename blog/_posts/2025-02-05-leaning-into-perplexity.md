---
layout: Post
date: 2025-02-05 14:02:07 +0000
title: "Leaning into Perplexity"
toc: true
image: /assets/images/perplexity-reasoning.png
description: 
mastodon_social_status_url: false
bluesky_status_url: false
tags:
  - llm
  - search
---

I had been [using Kagi](https://www.joshbeckman.org/blog/returning-to-kagi) for a while before [Perplexity](https://www.perplexity.ai)'s popularity really picked up.

I started experimenting with the LLM-assisted search capabilities of both (Kagi will do the same LLM summarization-with-sources that Perplexity solidified, if you end your query with a `?`) because I think "hard" sourcing with LLM distillation is the obvious best interface for really exploring a topic. As long as I read the summary *and* click through to read sources, I find that I always come away with a more complete understanding than I would have with a simple click through on the top link of a "traditional" search engine results page (SERP).

Now I find myself leaning more and more to using Perplexity to research ideas. It's admittedly better than Kagi's LLM summarization because Perplexity encourages and back-and-forth interrogation of the summary/sources, whereas Kagi just presents the summary and you have to restart with new context if you want to ask a further question.

Note: I'm just talking about Kagi's "Quick Answer" interface - they also  provide [The Assistant](https://help.kagi.com/kagi/ai/assistant.html), but:
1. It's only available on their top-tier plan (which I don't have the appetite for at the moment)
2. Its interface doesn't expose the reasoning and search steps that I've come to enjoy on Perplexity

Perplexity has been expanding the explanatory steps used to actually fulfill your query (see screenshot).
![Perplexity's Pro Search explanatory interface](/assets/images/perplexity-reasoning.png)

This kind of step-by-step, expandable by the user, leans _even more_ into the idea that the machine can present a summary that can be interrogated piece by piece. I love this because:
- it often leads me to a source other than the first presented by the LLM
- because it shows me how my phrasing/query was unclear (how I meant it vs. how it was interpreted by the LLM)
- it leads me to better use the system, creating a nice positive feedback loop

Honestly, there's never been a better time to be researching online. You just need to be [curious enough to articulate your thinking](https://www.joshbeckman.org/notes/846060336).
