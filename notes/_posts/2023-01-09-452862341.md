---
title: Note on What Is an Optimum Degree of LLM Hallucination? via Tyler Cowen
tags: llm
canonical: https://feeds.feedblitz.com/~/723782262/0/marginalrevolution~What-is-an-optimum-degree-of-LLM-hallucination.html
author: Tyler Cowen
author_id: 1df1d3fd6e8d4dace41241949a2db7b0
book: 23075791
book_title: What Is an Optimum Degree of LLM Hallucination?
hide_title: true
highlight_id: 452862341
readwise_url: https://readwise.io/open/452862341
image: https://marginalrevolution.com/wp-content/uploads/2016/10/MR-logo-thumbnail.png
favicon_url: https://s2.googleusercontent.com/s2/favicons?domain=feeds.feedblitz.com
source_emoji: "\U0001F310"
source_url: https://feeds.feedblitz.com/~/723782262/0/marginalrevolution~What-is-an-optimum-degree-of-LLM-hallucination.html#:~:text=Ideally%20you%20could,you%20as%20well%3F
serial_number: 2023.NTE.036
---
> Ideally you could adjust a dial and and set the degree of hallucination in advance.  For fact-checking you would choose zero hallucination, for poetry composition, life advice, and inspiration you might want more hallucination, to varying degrees of course.  After all, you don’t choose friends with zero hallucination, do you?  And you do read fiction, don’t you?
> 
> (Do note that you can ask the current version for references and follow-up — GPT is hardly as epistemically crippled as some people allege.)
> 
> In the meantime, I do not want an LLM with less hallucination.  The hallucinations are part of what I learn from.  I learn what the world would look like, if it were most in tune with the statistical model provided by text.  That to me is intrinsically interesting.  Does the matrix algebra version of the world not interest you as well?
> <div class="quoteback-footer"><div class="quoteback-avatar"><img class="mini-favicon" src="https://s2.googleusercontent.com/s2/favicons?domain=feeds.feedblitz.com"></div><div class="quoteback-metadata"><div class="metadata-inner"><span style="display:none">FROM:</span><div aria-label="Tyler Cowen" class="quoteback-author"> Tyler Cowen</div><div aria-label="What Is an Optimum Degree of LLM Hallucination?" class="quoteback-title"> What Is an Optimum Degree of LLM Hallucination?</div></div></div><div class="quoteback-backlink"><a target="_blank" aria-label="go to the full text of this quotation" rel="noopener" href="https://feeds.feedblitz.com/~/723782262/0/marginalrevolution~What-is-an-optimum-degree-of-LLM-hallucination.html#:~:text=Ideally%20you%20could,you%20as%20well%3F" class="quoteback-arrow"> Source</a></div></div>