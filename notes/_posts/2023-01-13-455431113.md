---
title: Note on How We Could Stumble Into AI Catastrophe via Cold Takes
tags: ai alignment
canonical: https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/
author: Cold Takes
author_id: ce4c0db4e36209320900cfde241e9477
book: 23226596
book_title: How We Could Stumble Into AI Catastrophe
hide_title: true
highlight_id: 455431113
readwise_url: https://readwise.io/open/455431113
image: https://www.cold-takes.com/content/images/2023/01/wile-c-coyote-twitter.png
favicon_url: https://s2.googleusercontent.com/s2/favicons?domain=www.cold-takes.com
source_emoji: "\U0001F310"
source_url: https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/#:~:text=The%20**King%20Lear,abdicating%20the%20throne.
serial_number: 2023.NTS.066
---
> The **King Lear problem**
> 
> The AI is **(actually) well-behaved when humans are in control.** Will this transfer to **when AIs are in control?**
> 
> It's hard to know how someone will behave when they have power over you, based only on observing how they behave when they don't.
> 
> AIs might behave as intended as long as humans are in control - but at some future point, AI systems might be capable and widespread enough to have opportunities to [take control of the world entirely](https://www.cold-takes.com/ai-could-defeat-all-of-us-combined/). It's hard to know whether they'll take these opportunities, and we can't exactly run a clean test of the situation.
> 
> Like King Lear trying to decide how much power to give each of his daughters before abdicating the throne.
> <div class="quoteback-footer"><div class="quoteback-avatar"><img class="mini-favicon" src="https://s2.googleusercontent.com/s2/favicons?domain=www.cold-takes.com"></div><div class="quoteback-metadata"><div class="metadata-inner"><span style="display:none">FROM:</span><div aria-label="Cold Takes" class="quoteback-author"> Cold Takes</div><div aria-label="How We Could Stumble Into AI Catastrophe" class="quoteback-title"> How We Could Stumble Into AI Catastrophe</div></div></div><div class="quoteback-backlink"><a target="_blank" aria-label="go to the full text of this quotation" rel="noopener" href="https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/#:~:text=The%20**King%20Lear,abdicating%20the%20throne." class="quoteback-arrow"> Source</a></div></div>