---
title: "Note on How We Could Stumble Into AI Catastrophe via Cold Takes"
tags: ai incentives alignment
canonical: https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/
author: Cold Takes
author_id: 1a2434952e956181
book: 23226596
book_title: "How We Could Stumble Into AI Catastrophe"
hide_title: true
highlight_id: 455437205
readwise_url: https://readwise.io/open/455437205
image: https://www.cold-takes.com/content/images/2023/01/wile-c-coyote-twitter.png
favicon_url: https://s2.googleusercontent.com/s2/favicons?domain=www.cold-takes.com
source_emoji: ðŸŒ
source_url: "https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/#:~:text=Maybe%20they%E2%80%99re%20just,into%20certain%20states%29."
---

> Maybe theyâ€™re just creating massive amounts of â€œdigital representations of human approval,â€ because this is what they were historically trained to seek (kind of like how humans sometimes do whatever it takes to get drugs that will get their brains into certain states).
> <div class="quoteback-footer"><div class="quoteback-avatar"><img class="mini-favicon" src="https://s2.googleusercontent.com/s2/favicons?domain=www.cold-takes.com"></div><div class="quoteback-metadata"><div class="metadata-inner"><span style="display:none">FROM:</span><div aria-label="Cold Takes" class="quoteback-author"> Cold Takes</div><div aria-label="How We Could Stumble Into AI Catastrophe" class="quoteback-title"> How We Could Stumble Into AI Catastrophe</div></div></div><div class="quoteback-backlink"><a target="_blank" aria-label="go to the full text of this quotation" rel="noopener" href="https://www.cold-takes.com/how-we-could-stumble-into-ai-catastrophe/#:~:text=Maybe%20they%E2%80%99re%20just,into%20certain%20states%29." class="quoteback-arrow"> Source</a></div></div>