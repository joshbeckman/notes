---
title: "More capable models can better recognize the specific circum..."
tags: llm
canonical: https://simonwillison.net/2023/Apr/7/chatgpt-lies/
author: Simon Willison
book: 26165418
book_title: "We Need to Tell People ChatGPT Will Lie to Them, Not Debate Linguistics"
book_asin: 
hide_title: true
readwise_url: https://readwise.io/open/504985991
image: https://news.ycombinator.com/favicon.ico
favicon_url: https://s2.googleusercontent.com/s2/favicons?domain=simonwillison.net
source_emoji: 🌐
source_url: "https://simonwillison.net/2023/Apr/7/chatgpt-lies/#:~:text=More%20capable%20models,be%20less%20educated."
---

> More capable models can better recognize the specific circumstances under which they are trained. Because of this, they are more likely to learn to act as expected in precisely those circumstances while behaving competently but unexpectedly in others. This can surface in the form of problems that Perez et al. (2022) call sycophancy, where a model answers subjective questions in a way that flatters their user’s stated beliefs, and sandbagging, where models are more likely to endorse common misconceptions when their user appears to be less educated.
> <div class="quoteback-footer"><div class="quoteback-avatar"><img class="mini-favicon" src="https://s2.googleusercontent.com/s2/favicons?domain=simonwillison.net"></div><div class="quoteback-metadata"><div class="metadata-inner"><span style="display:none">FROM:</span><div aria-label="Simon Willison" class="quoteback-author"> Simon Willison</div><div aria-label="We Need to Tell People ChatGPT Will Lie to Them, Not Debate Linguistics" class="quoteback-title"> We Need to Tell People ChatGPT Will Lie to Them, Not Debate Linguistics</div></div></div><div class="quoteback-backlink"><a target="_blank" aria-label="go to the full text of this quotation" rel="noopener" href="https://simonwillison.net/2023/Apr/7/chatgpt-lies/#:~:text=More%20capable%20models,be%20less%20educated." class="quoteback-arrow"> Source</a></div></div>