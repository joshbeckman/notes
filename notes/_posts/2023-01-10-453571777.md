---
title: 'Note on Import AI 314: Language Models + Text-to-Speech; Emergent Cooperation
  in Wargames; ICML Bans LLM-written Papers via Jack Clark'
tags: optimization
canonical: https://jack-clark.net/2023/01/09/import-ai-314-language-models-text-to-speech-emergent-cooperation-in-wargames-icml-bans-llm-written-papers/
author: Jack Clark
author_id: c054117ddd4c756958b5590b432f59fd
book: 23119910
book_title: 'Import AI 314: Language Models + Text-to-Speech; Emergent Cooperation
  in Wargames; ICML Bans LLM-written Papers'
hide_title: true
highlight_id: 453571777
readwise_url: https://readwise.io/open/453571777
image: https://s0.wp.com/i/blank.jpg
favicon_url: https://s2.googleusercontent.com/s2/favicons?domain=jack-clark.net
source_emoji: "\U0001F310"
source_url: https://jack-clark.net/2023/01/09/import-ai-314-language-models-text-to-speech-emergent-cooperation-in-wargames-icml-bans-llm-written-papers/#:~:text=This%20is%20an,retraining%20the%20model*.
serial_number: 2023.NTE.042
---
> This is an example of the ‘capability overhang’ phenomenon I’ve been talking about re language models for a while – existing LLMs are *far more capable than we think*. All it takes is some experimentation and finding experts to find new ways to phrase questions and you can wind up with extraordinarily powerful capability jumps *without retraining the model*.
> <div class="quoteback-footer"><div class="quoteback-avatar"><img class="mini-favicon" src="https://s2.googleusercontent.com/s2/favicons?domain=jack-clark.net"></div><div class="quoteback-metadata"><div class="metadata-inner"><span style="display:none">FROM:</span><div aria-label="Jack Clark" class="quoteback-author"> Jack Clark</div><div aria-label="Import AI 314: Language Models + Text-to-Speech; Emergent Cooperation in Wargames; ICML Bans LLM-written Papers" class="quoteback-title"> Import AI 314: Language Models + Text-to-Speech; Emergent Cooperation in Wargames; ICML Bans LLM-written Papers</div></div></div><div class="quoteback-backlink"><a target="_blank" aria-label="go to the full text of this quotation" rel="noopener" href="https://jack-clark.net/2023/01/09/import-ai-314-language-models-text-to-speech-emergent-cooperation-in-wargames-icml-bans-llm-written-papers/#:~:text=This%20is%20an,retraining%20the%20model*." class="quoteback-arrow"> Source</a></div></div>

Optimization of input can be done in parallel to optimization of the model.