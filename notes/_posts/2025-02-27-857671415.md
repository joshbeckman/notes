---
title: Note on This Is Interesting as a First Large Diffusion-Based LLM via Andrej
  Karpathy
tags: llm machine-learning
canonical: https://x.com/karpathy/status/1894923254864978091?s=46
author: Andrej Karpathy
author_id: 4c403b237e3599d8b28a013d30b458be
book: 49194504
book_title: This Is Interesting as a First Large Diffusion-Based LLM
hide_title: true
highlight_id: 857671415
readwise_url: https://readwise.io/open/857671415
image: https://pbs.twimg.com/profile_images/1296667294148382721/9Pr6XrPB.jpg
favicon_url: https://s2.googleusercontent.com/s2/favicons?domain=x.com
source_emoji: "\U0001F310"
source_url: https://x.com/karpathy/status/1894923254864978091?s=46#:~:text=This%20is%20interesting,strengths%20and%20weaknesses.
serial_number: 2025.NTE.029
---
> This is interesting as a first large diffusion-based LLM.
> 
> Most of the LLMs you've been seeing are ~clones as far as the core modeling approach goes. They're all trained "autoregressively", i.e. predicting tokens from left to right. Diffusion is different - it doesn't go left to right, but all at once. You start with noise and gradually denoise into a token stream.
> 
> Most of the image / video generation AI tools actually work this way and use Diffusion, not Autoregression. It's only text (and sometimes audio!) that have resisted. So it's been a bit of a mystery to me and many others why, for some reason, text prefers Autoregression, but images/videos prefer Diffusion. This turns out to be a fairly deep rabbit hole that has to do with the distribution of information and noise and our own perception of them, in these domains. If you look close enough, a lot of interesting connections emerge between the two as well.
> 
> All that to say that this model has the potential to be different, and possibly showcase new, unique psychology, or new strengths and weaknesses.
> <div class="quoteback-footer"><div class="quoteback-avatar"><img class="mini-favicon" src="https://s2.googleusercontent.com/s2/favicons?domain=x.com"></div><div class="quoteback-metadata"><div class="metadata-inner"><span style="display:none">FROM:</span><div aria-label="Andrej Karpathy" class="quoteback-author"> Andrej Karpathy</div><div aria-label="This Is Interesting as a First Large Diffusion-Based LLM" class="quoteback-title"> This Is Interesting as a First Large Diffusion-Based LLM</div></div></div><div class="quoteback-backlink"><a target="_blank" aria-label="go to the full text of this quotation" rel="noopener" href="https://x.com/karpathy/status/1894923254864978091?s=46#:~:text=This%20is%20interesting,strengths%20and%20weaknesses." class="quoteback-arrow"> Source</a></div></div>

It's very cool to watch the text generation-via-diffusion. Like focusing your eyes slowly to resolve a book all at once instead of writing it word-by-word.