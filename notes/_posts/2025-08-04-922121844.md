---
title: Note on Building Proactive AI Agents - By Bryan Houlton via Bryan Houlton
tags: llm
canonical: https://bryanhoulton1.substack.com/p/building-proactive-ai-agents
author: Bryan Houlton
author_id: 4252662829b3ffec253d93f40aae211d
book: 53911616
book_title: Building Proactive AI Agents - By Bryan Houlton
hide_title: true
highlight_id: 922121844
readwise_url: https://readwise.io/open/922121844
image: https://substackcdn.com/image/fetch/w_1200,h_600,c_fill,f_jpg,q_auto:good,fl_progressive:steep,g_auto/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F31519d74-254e-4d32-88d8-734239fa59cb_1026x948.png
favicon_url: https://s2.googleusercontent.com/s2/favicons?domain=bryanhoulton1.substack.com
source_emoji: "\U0001F310"
source_url: https://bryanhoulton1.substack.com/p/building-proactive-ai-agents#:~:text=To%20do%20that,number%20of%20interactions.
serial_number: 2025.NTE.115
---
> To do that we introduce decaying resolution, turning our memory into DRM. Instead of just having a short term or long term memory, Orin’s memory computes sliding window summaries over the ground truth memories. At any given point in time, Orin’s memory looks like something this:
> 
> 1.  Direct interaction summaries for today’s interactions. This allows Orin to have a very high resolution memory for everything that happened today.
>     
> 2.  Daily summaries for what happened in the past two weeks. These summaries are built from the direct interaction summaries each day.
>     
> 3.  Weekly summaries for the past ten weeks (excluding the past two weeks). These are built from daily summaries.
>     
> 4.  Monthly summaries for everything more than ten weeks old.
>     
> 
> When computing this memory, everything is timestamped and timezones are normalized for the user’s timezone.
> 
> As you can see, this can work really well to keep a history of what happened. Orin won’t remember the exact lesson timings from last year, but that’s fine. Instead, he’ll remember that a student was struggling with algebra in July and that they were prepping for a big test - that’s the information we care about.
> 
> The best part is that DRM scales tokens sublinearly with the number of interactions.
> <div class="quoteback-footer"><div class="quoteback-avatar"><img class="mini-favicon" src="https://s2.googleusercontent.com/s2/favicons?domain=bryanhoulton1.substack.com"></div><div class="quoteback-metadata"><div class="metadata-inner"><span style="display:none">FROM:</span><div aria-label="Bryan Houlton" class="quoteback-author"> Bryan Houlton</div><div aria-label="Building Proactive AI Agents - By Bryan Houlton" class="quoteback-title"> Building Proactive AI Agents - By Bryan Houlton</div></div></div><div class="quoteback-backlink"><a target="_blank" aria-label="go to the full text of this quotation" rel="noopener" href="https://bryanhoulton1.substack.com/p/building-proactive-ai-agents#:~:text=To%20do%20that,number%20of%20interactions." class="quoteback-arrow"> Source</a></div></div>

They call this “decaying-resolution memory.” I would recommend pairing this with an MCP tool to get specific chats on a specific date to hydrate a vague old memory. 

I think this also demonstrates why "sleep" is necessary for agents/entities to "learn." By turning them off and back on again, we give a chance for memory to be compacted and context to be freed up.