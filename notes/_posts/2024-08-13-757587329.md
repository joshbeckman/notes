---
title: 'Note on AI #76: Six Shorts Stories About OpenAI via TheZvi'
tags: llm research bias ai validation ethics
canonical: https://thezvi.wordpress.com/2024/08/08/ai-76-six-shorts-stories-about-openai/
author: TheZvi
author_id: 10851c5165482b1779d34314facc0f2b
book: 43122431
book_title: 'AI #76: Six Shorts Stories About OpenAI'
hide_title: true
highlight_id: 757587329
readwise_url: https://readwise.io/open/757587329
image: https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F9d10b1d0-8af4-4504-9f30-9cdd3404c4c5_1595x1118.jpeg
favicon_url: https://s2.googleusercontent.com/s2/favicons?domain=thezvi.wordpress.com
source_emoji: "\U0001F310"
source_url: https://thezvi.wordpress.com/2024/08/08/ai-76-six-shorts-stories-about-openai/#:~:text=There%20are%20some,with%20%E2%80%98wording-adjusted%E2%80%99%20results.
serial_number: 2024.NTE.145
---
> There are some whitepapaers showing that LLMs [predict the results of social science survey experiments](https://x.com/RobbWiller/status/1821271270182547916), [with (r = 0.85, adj r = 0.91) across 70 studies](https://t.co/1M5aydRMyH), with (r = .9, adj r = .94) for the unpublished studies. If these weren’t surveys I would be highly suspicious because this would be implying the results could reliably replicate at all. If it’s only surveys, sure, I suppose surveys should replicate.
> 
> This suggests that we mostly do not actually need the surveys, we can get close (r ~ 0.9) by asking GPT-4, and that will only improve over time.
> 
> This also suggests that we can use this to measure question bias and framing. You can simulate five different versions of the survey, and see how the simulated responses change. This could also let one do a meta-analysis of sorts, with ‘wording-adjusted’ results.
> <div class="quoteback-footer"><div class="quoteback-avatar"><img class="mini-favicon" src="https://s2.googleusercontent.com/s2/favicons?domain=thezvi.wordpress.com"></div><div class="quoteback-metadata"><div class="metadata-inner"><span style="display:none">FROM:</span><div aria-label="TheZvi" class="quoteback-author"> TheZvi</div><div aria-label="AI #76: Six Shorts Stories About OpenAI" class="quoteback-title"> AI #76: Six Shorts Stories About OpenAI</div></div></div><div class="quoteback-backlink"><a target="_blank" aria-label="go to the full text of this quotation" rel="noopener" href="https://thezvi.wordpress.com/2024/08/08/ai-76-six-shorts-stories-about-openai/#:~:text=There%20are%20some,with%20%E2%80%98wording-adjusted%E2%80%99%20results." class="quoteback-arrow"> Source</a></div></div>

I would expect this to work only for topics that people have expressed opinions about in the corpus/training text. But still! The bias calibration alone is very useful.