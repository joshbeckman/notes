---
layout: Post
date: '2025-10-09 17:09:59 +0000'
title: New comment by bckmn in 'Two things LLM coding agents are still bad at'
toc: true
image: https://news.ycombinator.com/y18.svg
description:
canonical: https://news.ycombinator.com/item?id=45530413
in_reply_to: https://news.ycombinator.com/item?id=45530413
hacker_news_url: https://news.ycombinator.com/item?id=45530413
tags:
- code-snippets
- software-engineering
- research
- programming-languages
- ai
- LLM
- hacker-news
serial_number: 2025.RPY.020
---
<p>I think asking your questions in that form is akin to "sorting prompts" that I learned about from <a href="https://mikecaulfield.substack.com/p/is-the-llm-response-wrong-or-have" rel="nofollow">https://mikecaulfield.substack.com/p/is-the-llm-response-wro...</a> and I have been using successfully when when writing code (e.g. [as a Claude code slash command](<a href="https://www.joshbeckman.org/notes/936274709" rel="nofollow">https://www.joshbeckman.org/notes/936274709</a>)).<p>Essentially, you're asking the LLM to do research and categorize/evaluate that research <i>instead</i> of just giving you an answer. The "work" of accessing, summarizing, and valuing the research yields a more accurate result.</p>
